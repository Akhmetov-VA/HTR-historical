{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T13:04:06.915521Z",
     "start_time": "2024-03-06T13:03:59.031706Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datasets import load_metric\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    default_data_collator\n",
    ")\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T12:54:59.546091Z",
     "start_time": "2024-03-06T12:54:59.394746Z"
    }
   },
   "id": "d15947033864af6d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "Error while deserializing header: MetadataIncompleteBuffer",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSafetensorError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Инициализируем распознавание текста\u001B[39;00m\n\u001B[0;32m      2\u001B[0m processor \u001B[38;5;241m=\u001B[39m TrOCRProcessor\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraxtemur/trocr-base-ru\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mVisionEncoderDecoderModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../../models/text_recognizer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mF:\\WORKING_PROJECTS\\RANEPA\\Historical-docs-OCR\\.venv\\lib\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py:359\u001B[0m, in \u001B[0;36mVisionEncoderDecoderModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    353\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    354\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFast initialization is currently not supported for VisionEncoderDecoderModel. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    355\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFalling back to slow initialization...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    356\u001B[0m     )\n\u001B[0;32m    357\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_fast_init\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 359\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\WORKING_PROJECTS\\RANEPA\\Historical-docs-OCR\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:3503\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3483\u001B[0m     resolved_archive_file, sharded_metadata \u001B[38;5;241m=\u001B[39m get_checkpoint_shard_files(\n\u001B[0;32m   3484\u001B[0m         pretrained_model_name_or_path,\n\u001B[0;32m   3485\u001B[0m         resolved_archive_file,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3495\u001B[0m         _commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[0;32m   3496\u001B[0m     )\n\u001B[0;32m   3498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3499\u001B[0m     is_safetensors_available()\n\u001B[0;32m   3500\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resolved_archive_file, \u001B[38;5;28mstr\u001B[39m)\n\u001B[0;32m   3501\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m resolved_archive_file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.safetensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3502\u001B[0m ):\n\u001B[1;32m-> 3503\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msafe_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m   3504\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mmetadata()\n\u001B[0;32m   3506\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m metadata\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mSafetensorError\u001B[0m: Error while deserializing header: MetadataIncompleteBuffer"
     ]
    }
   ],
   "source": [
    "# Инициализируем распознавание текста\n",
    "processor = TrOCRProcessor.from_pretrained(\"raxtemur/trocr-base-ru\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"../../models/text_recognizer\", local_files_only=True)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T13:23:47.677198Z",
     "start_time": "2024-03-06T13:23:36.928870Z"
    }
   },
   "id": "c3ca83a3f31e3bbc",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_detector = YOLO(\"../../models/new_text_detector/best.pt\").to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T13:04:46.811118Z",
     "start_time": "2024-03-06T13:04:46.374157Z"
    }
   },
   "id": "81c98bcdefb443fa",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def get_rand_image():\n",
    "    path = pathlib.Path(\"../../data/raw/Распознавание текстов/Уставные грамоты в jpg (Просветов)\")\n",
    "    return np.random.choice(list(path.iterdir()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T13:08:04.329181Z",
     "start_time": "2024-03-06T13:08:04.311372Z"
    }
   },
   "id": "6dfe665a9f58cd05",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 256x192 12 texts, 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 6.0ms postprocess per image at shape (1, 3, 256, 192)\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "# img = Image.open(r\"../../data/raw/Распознавание текстов/Уставные грамоты в jpg (Просветов)/11227024_doc1.jpg\")\n",
    "img = Image.open(get_rand_image())\n",
    "img = ImageOps.exif_transpose(img)\n",
    "\n",
    "res = text_detector.predict([img])\n",
    "\n",
    "# Process results list\n",
    "for result in res:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    result.show()  # display to screen"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T13:18:37.590383Z",
     "start_time": "2024-03-06T13:18:30.556923Z"
    }
   },
   "id": "9a2f929a94efa7b6",
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
