{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T13:03:32.619738Z",
     "start_time": "2024-03-27T13:03:32.608738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import supervision as sv\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50084a8c998f08b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:42:19.643234Z",
     "start_time": "2024-03-27T11:42:19.353232Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "############# Формируем датасет из каталога Победоносцев (разметка сегментами) #############\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "image_dir = \"../../data/raw/Распознавание текстов/Победоносцев/images\"\n",
    "# annotation_file = \"../../data/raw/Распознавание текстов/Победоносцев/project-14-at-2024-03-18-16-02-b43f1e84.json\"\n",
    "annotation_file = '../../data/raw/Распознавание текстов/Победоносцев/project-14-at-2024-03-27-22-12-07be0e2d.json'\n",
    "segment_annotations = pd.read_json(annotation_file)\n",
    "\n",
    "segment_images = []\n",
    "\n",
    "# Перебор всех файлов изображений в image_dir\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        image_path = os.path.join(root, file)\n",
    "        segment_images.append(image_path)\n",
    "        \n",
    "train_images, test_images = train_test_split(segment_images, test_size=0.2, random_state=42)\n",
    "train_images, valid_images = train_test_split(train_images, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Пути для сохранения разделенных выборок\n",
    "images_text_segmenter_train_dir = \"../../data/processed/4 Segmenter test/text_segmenter/train/images\"\n",
    "labels_text_segmenter_train_dir = \"../../data/processed/4 Segmenter test/text_segmenter/train/labels\"\n",
    "\n",
    "images_text_segmenter_valid_dir = \"../../data/processed/4 Segmenter test/text_segmenter/valid/images\"\n",
    "labels_text_segmenter_valid_dir = \"../../data/processed/4 Segmenter test/text_segmenter/valid/labels\"\n",
    "\n",
    "images_text_segmenter_test_dir = \"../../data/processed/4 Segmenter test/text_segmenter/test/images\"\n",
    "labels_text_segmenter_test_dir = \"../../data/processed/4 Segmenter test/text_segmenter/test/labels\"\n",
    "\n",
    "images_text_recognizer_train_dir = \"../../data/processed/4 Segmenter test/text_recognizer/train\"\n",
    "\n",
    "images_text_recognizer_valid_dir = \"../../data/processed/4 Segmenter test/text_recognizer/valid\"\n",
    "\n",
    "images_text_recognizer_test_dir = \"../../data/processed/4 Segmenter test/text_recognizer/test\"\n",
    "\n",
    "csv_root_path = \"../../data/processed/4 Segmenter test\"\n",
    "\n",
    "# Создание каталогов для train, valid, test и images\n",
    "os.makedirs(images_text_segmenter_train_dir, exist_ok=True)\n",
    "os.makedirs(labels_text_segmenter_train_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(images_text_segmenter_valid_dir, exist_ok=True)\n",
    "os.makedirs(labels_text_segmenter_valid_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(images_text_segmenter_test_dir, exist_ok=True)\n",
    "os.makedirs(labels_text_segmenter_test_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(images_text_recognizer_train_dir, exist_ok=True)\n",
    "os.makedirs(images_text_recognizer_valid_dir, exist_ok=True)\n",
    "os.makedirs(images_text_recognizer_test_dir , exist_ok=True)\n",
    "\n",
    "\n",
    "# Указываем директории и файл с аннотациями\n",
    "image_dir = Path(\"../../data/raw/Распознавание текстов/Победоносцев/images\")\n",
    "annotation_file = Path('../../data/raw/Распознавание текстов/Победоносцев/project-14-at-2024-03-27-22-12-07be0e2d.json')\n",
    "\n",
    "# Проверяем, существует ли файл аннотаций\n",
    "if not annotation_file.exists():\n",
    "    raise FileNotFoundError(f\"Annotation file not found: {annotation_file}\")\n",
    "\n",
    "# Читаем файл с аннотациями\n",
    "segment_annotations = pd.read_json(annotation_file)\n",
    "\n",
    "# Инициализируем список для хранения путей к изображениям\n",
    "segment_images = []\n",
    "\n",
    "# Перебор всех файлов изображений в image_dir\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            image_path = Path(root) / file\n",
    "            segment_images.append(image_path)\n",
    "\n",
    "# Проверка на пустой список изображений\n",
    "if not segment_images:\n",
    "    raise ValueError(f\"No valid image files found in directory: {image_dir}\")\n",
    "\n",
    "# Рандомизация списка изображений перед разделением\n",
    "random.shuffle(segment_images)\n",
    "\n",
    "# Разделяем на тренировочный, тестовый и валидационный наборы\n",
    "train_images, test_images = train_test_split(segment_images, test_size=0.2, random_state=42)\n",
    "train_images, valid_images = train_test_split(train_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Дополнительная проверка на синхронизацию аннотаций и изображений\n",
    "train_images = [img for img in train_images if img.name in segment_annotations['file_upload'].values]\n",
    "valid_images = [img for img in valid_images if img.name in segment_annotations['file_upload'].values]\n",
    "test_images = [img for img in test_images if img.name in segment_annotations['file_upload'].values]\n",
    "\n",
    "# Выводим количество изображений в каждом наборе\n",
    "print(f\"Train set size: {len(train_images)}\")\n",
    "print(f\"Validation set size: {len(valid_images)}\")\n",
    "print(f\"Test set size: {len(test_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_annotations['file_upload'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ebb2e9a290e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:42:19.659385Z",
     "start_time": "2024-03-27T11:42:19.643234Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Размер обучающей выборки: {len(train_images):>6} \\n\"\n",
    "    f\"Размер валидационной выборки: {len(valid_images)} \\n\"\n",
    "    f\"Размер тестовой выборки: {len(test_images):>7}\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd129757060cea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826a024e96dd266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:42:31.313818Z",
     "start_time": "2024-03-27T11:42:31.298818Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Получаем список ID с лейблом \"Перечеркнутый текст\", чтобы не включать в обучение т.к. слишком мало данных (всего 5 строк)\n",
    "\n",
    "id_to_skip = []\n",
    "\n",
    "for row_id, annotations in segment_annotations[[\"annotations\"]].iterrows():\n",
    "    for annotations_file in annotations.values[0]:\n",
    "        for annotation in annotations_file[\"result\"]:\n",
    "            annotation_id = annotation[\"id\"]\n",
    "            if annotation[\"type\"] == \"labels\":\n",
    "                if annotation[\"value\"][\"labels\"][0] == \"Перечеркнутый текст\":\n",
    "                    id_to_skip.append(annotation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список ID с лейблом \"Перечеркнутый текст\", чтобы не включать в обучение т.к. слишком мало данных (всего 5 строк)\n",
    "id_to_skip = []\n",
    "\n",
    "# Функция для обработки каждой строки DataFrame\n",
    "def check_annotations(row):\n",
    "    for annotations_file in row[\"annotations\"]:\n",
    "        if \"result\" in annotations_file:\n",
    "            for annotation in annotations_file[\"result\"]:\n",
    "                if annotation.get(\"type\") == \"labels\":\n",
    "                    labels = annotation.get(\"value\", {}).get(\"labels\", [])\n",
    "                    if labels and labels[0] == \"Перечеркнутый текст\":\n",
    "                        id_to_skip.append(annotation[\"id\"])\n",
    "\n",
    "# Применяем функцию ко всему DataFrame\n",
    "segment_annotations.apply(check_annotations, axis=1)\n",
    "id_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf43bdb9aa82f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:42:43.154654Z",
     "start_time": "2024-03-27T11:42:42.971654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Формируем датасет в pandas\n",
    "\n",
    "text = []\n",
    "points = []\n",
    "orig_points = []\n",
    "images = []\n",
    "\n",
    "for row_id, (annotations, image_name) in segment_annotations[[\"annotations\", \"file_upload\"]].iterrows():\n",
    "    for annotations_file in annotations:\n",
    "        for annotation in annotations_file[\"result\"]:\n",
    "            # Пропускаем разметку с перечеркнутым текстом\n",
    "            if annotation[\"id\"] in id_to_skip:\n",
    "                continue\n",
    "            if annotation[\"type\"] == \"textarea\":\n",
    "                # сохраняем текст разметки\n",
    "                text.append(annotation[\"value\"][\"text\"][0])\n",
    "                # нормируем и сохраняем координаты маски\n",
    "                width = annotation[\"original_width\"]\n",
    "                height = annotation[\"original_height\"]\n",
    "                norm_points = []\n",
    "                yolo_points = []\n",
    "                for non_norm_points in annotation[\"value\"][\"points\"]:\n",
    "                    norm_points.append([\n",
    "                        (non_norm_points[1] * height) / 100,\n",
    "                        (non_norm_points[0] * width) / 100\n",
    "                    ])\n",
    "                    yolo_points.append([\n",
    "                        non_norm_points[0] / 100,\n",
    "                        non_norm_points[1] / 100\n",
    "                    ])\n",
    "\n",
    "                points.append(norm_points)\n",
    "                orig_points.append(yolo_points)\n",
    "                images.append(image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e323040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обработки одной аннотации\n",
    "def process_annotation(annotation, image_name, id_to_skip, text, points, orig_points, images):\n",
    "    # Пропускаем аннотацию, если ее ID находится в списке id_to_skip\n",
    "    if annotation.get(\"id\") in id_to_skip:\n",
    "        return\n",
    "\n",
    "    if annotation.get(\"type\") == \"textarea\":\n",
    "        # Проверяем, что текстовое поле не пустое\n",
    "        if annotation.get(\"value\", {}).get(\"text\"):\n",
    "            text.append(annotation[\"value\"][\"text\"][0])\n",
    "        else:\n",
    "            return  # Если текст пустой, пропускаем\n",
    "\n",
    "        # Получаем размеры изображения и проверяем их наличие\n",
    "        width = annotation.get(\"original_width\")\n",
    "        height = annotation.get(\"original_height\")\n",
    "        if not width or not height:\n",
    "            return  # Пропускаем аннотацию, если размеры не указаны\n",
    "\n",
    "        # Масштабируем и сохраняем координаты маски\n",
    "        norm_points = []\n",
    "        yolo_points = []\n",
    "        for non_norm_points in annotation.get(\"value\", {}).get(\"points\", []):\n",
    "            norm_points.append([\n",
    "                (non_norm_points[1] * height) / 100,\n",
    "                (non_norm_points[0] * width) / 100\n",
    "            ])\n",
    "            yolo_points.append([\n",
    "                non_norm_points[0] / 100,\n",
    "                non_norm_points[1] / 100\n",
    "            ])\n",
    "\n",
    "        points.append(norm_points)\n",
    "        orig_points.append(yolo_points)\n",
    "        images.append(image_name)\n",
    "\n",
    "# Формируем датасет\n",
    "text = []\n",
    "points = []\n",
    "orig_points = []\n",
    "images = []\n",
    "\n",
    "# Обработка каждой строки DataFrame\n",
    "for row_id, (annotations, image_name) in segment_annotations[[\"annotations\", \"file_upload\"]].iterrows():\n",
    "    for annotations_file in annotations:\n",
    "        for annotation in annotations_file.get(\"result\", []):\n",
    "            process_annotation(annotation, image_name, id_to_skip, text, points, orig_points, images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e78b2eec25c3b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:42:54.793286Z",
     "start_time": "2024-03-27T11:42:54.778671Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data={\n",
    "    \"text\": text,\n",
    "    \"points\": points,\n",
    "    \"orig_points\": orig_points,\n",
    "    \"image\": images\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ae002",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_data = data.groupby(\"image\").agg({\"points\": list, \"orig_points\": list, \"text\": list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ca1cde843e394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T12:53:15.428418Z",
     "start_time": "2024-03-27T12:53:13.271003Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yolo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9112bf1506ad75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T11:43:18.179870Z",
     "start_time": "2024-03-27T11:43:18.165773Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def crop_and_save_polygon(image_path, out_path, polygon_coords, bbox=None):\n",
    "    # Загружаем изображение\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Определяем средний цвет изображения для заливки\n",
    "    mean_color = np.array(cv2.mean(image)).astype(int)[:3]\n",
    "    \n",
    "    # Возвращаем на место перепутанные местами координаты yx->xy\n",
    "    res = []\n",
    "    for y, x in polygon_coords:\n",
    "        res.append([x, y])\n",
    "    \n",
    "    # Преобразуем координаты полигона в формат, понятный OpenCV\n",
    "    pts = np.array(res, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    \n",
    "    # Создаем маску, которая соответствует области полигона\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [pts], 0, 255, -1)\n",
    "    \n",
    "    # Вырезаем область изображения, соответствующую маске\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Заливаем чёрные области тем цветом, который был подан на вход функции\n",
    "    result[mask==0] = mean_color\n",
    "    \n",
    "    # Если задан bbox, обрежем изображение по этим координатам\n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        result = result[y1:y2, x1:x2]\n",
    "    \n",
    "    cv2.imwrite(out_path, result)\n",
    "    \n",
    "\n",
    "def convert_mask_to_xy_bbox(mask):\n",
    "    # Конвертируем полигон в bbox\n",
    "    bounding_boxes = sv.polygon_to_xyxy(mask).astype(int)\n",
    "    # Возвращаем на место перепутанные местами координаты yx->xy\n",
    "    res_bbox = [bounding_boxes[1], bounding_boxes[0], bounding_boxes[3], bounding_boxes[2]]\n",
    "    return res_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Предполагается, что модуль `sv` импортирован где-то выше\n",
    "# import sv\n",
    "\n",
    "def crop_and_save_polygon(image_path, out_path, polygon_coords, bbox=None):\n",
    "    # Загружаем изображение\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image at {image_path}\")\n",
    "    \n",
    "    # Определяем средний цвет изображения для заливки\n",
    "    mean_color = np.array(cv2.mean(image)).astype(int)[:3]\n",
    "    \n",
    "    # Преобразуем координаты полигона из [y, x] в [x, y]\n",
    "    res = [[x, y] for y, x in polygon_coords]\n",
    "    \n",
    "    # Преобразуем координаты полигона в формат, понятный OpenCV\n",
    "    pts = np.array(res, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    \n",
    "    # Создаем маску, которая соответствует области полигона\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [pts], 0, 255, -1)\n",
    "    \n",
    "    # Вырезаем область изображения, соответствующую маске\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Заливаем чёрные области средним цветом изображения\n",
    "    result[mask==0] = mean_color\n",
    "    \n",
    "    # Если задан bbox, обрезаем изображение по этим координатам\n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1, y1 = max(x1, 0), max(y1, 0)\n",
    "        x2, y2 = min(x2, image.shape[1]), min(y2, image.shape[0])\n",
    "        result = result[y1:y2, x1:x2]\n",
    "    \n",
    "    cv2.imwrite(out_path, result)\n",
    "\n",
    "def convert_mask_to_xy_bbox(mask):\n",
    "    # Конвертируем полигон в bbox\n",
    "    bounding_boxes = sv.polygon_to_xyxy(mask).astype(int)\n",
    "    # Преобразуем из [y1, x1, y2, x2] в [x1, y1, x2, y2]\n",
    "    res_bbox = [bounding_boxes[1], bounding_boxes[0], bounding_boxes[3], bounding_boxes[2]]\n",
    "    return res_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48631fcd88eb3f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T14:16:05.607246Z",
     "start_time": "2024-03-27T14:08:30.256561Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data_images, (images_data_dir, labels_data_dir), recognizer_images_path, csv_name in tqdm(zip(\n",
    "        [train_images, valid_images, test_images], \n",
    "        [\n",
    "            [images_text_segmenter_train_dir, labels_text_segmenter_train_dir],\n",
    "            [images_text_segmenter_valid_dir, labels_text_segmenter_valid_dir],\n",
    "            [images_text_segmenter_test_dir, labels_text_segmenter_test_dir]\n",
    "        ],\n",
    "        [images_text_recognizer_train_dir, images_text_recognizer_valid_dir, images_text_recognizer_test_dir],\n",
    "        [\"train.csv\", \"valid.csv\", \"test.csv\"]\n",
    "), total=3):  \n",
    "    \n",
    "    objects = []\n",
    "    \n",
    "    for image in data_images:\n",
    "        image_path = Path(image)\n",
    "        image_name = image_path.name\n",
    "        image_suffix = image_path.suffix\n",
    "        \n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "        # # # # # # #   Датасет для сегментации   # # # # # #\n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "        \n",
    "        skip_ocr = False\n",
    "        \n",
    "        # копируем изображение\n",
    "        shutil.copy(image, images_data_dir)\n",
    "        image_label_path = Path(labels_data_dir) / Path(image_name.replace(image_suffix, \".txt\"))\n",
    "        # создаём файл с разметкой этого изображения\n",
    "        with open(image_label_path, \"w\") as file:\n",
    "                for line in yolo_data[yolo_data[\"image\"] == image_name][\"orig_points\"].values[0]:\n",
    "                    if np.array(line).shape[1] > 2:\n",
    "                        line = line.tolist()\n",
    "                    file.write(\"0 \" + ' '.join(f\"{item[0]} {item[1]}\" for item in line) + \"\\n\")\n",
    "\n",
    "                \n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # # #  \n",
    "        # # # # # # #   Датасет для распознавания   # # # # # #\n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "        \n",
    "        if not skip_ocr:\n",
    "            ocr_masks, texts = [*yolo_data[yolo_data[\"image\"] == image_name][[\"points\", \"text\"]].values[0].tolist()]\n",
    "            for num_mask, [mask, text] in enumerate(zip(ocr_masks, texts)):\n",
    "                bbox = convert_mask_to_xy_bbox(mask)\n",
    "                filename = Path(f\"{num_mask}_{Path(image).name}\")\n",
    "                out_path = Path(recognizer_images_path) / filename\n",
    "                crop_and_save_polygon(image, str(out_path), mask, bbox)\n",
    "                \n",
    "                objects.append({\"file_name\": filename, \"text\": text})\n",
    "    \n",
    "    ocr_data = pd.DataFrame(objects)\n",
    "    ocr_data.to_csv(f\"{csv_root_path}/{csv_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_image_data(yolo_data, train_images, valid_images, test_images, \n",
    "                       segment_dirs, recognizer_dirs, csv_names, csv_root_path):\n",
    "    \n",
    "    for data_images, (images_data_dir, labels_data_dir), recognizer_images_path, csv_name in tqdm(\n",
    "            zip([train_images, valid_images, test_images], \n",
    "                segment_dirs, recognizer_dirs, csv_names), total=3):\n",
    "\n",
    "        objects = []\n",
    "\n",
    "        for image in data_images:\n",
    "            image_path = Path(image)\n",
    "            image_name = image_path.name\n",
    "            image_suffix = image_path.suffix\n",
    "\n",
    "            # Загружаем соответствующие аннотации\n",
    "            image_annotations = yolo_data[yolo_data[\"image\"] == image_name]\n",
    "            if image_annotations.empty:\n",
    "                print(f\"Warning: No annotations found for image {image_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Копируем изображение в директорию сегментации\n",
    "            shutil.copy(image, images_data_dir)\n",
    "            image_label_path = Path(labels_data_dir) / image_name.replace(image_suffix, \".txt\")\n",
    "\n",
    "            # Создаем файл с разметкой для сегментации\n",
    "            with open(image_label_path, \"w\") as file:\n",
    "                for line in image_annotations[\"orig_points\"].values[0]:\n",
    "                    if len(line[0]) > 2:\n",
    "                        line = line.tolist()\n",
    "                    file.write(\"0 \" + ' '.join(f\"{item[0]} {item[1]}\" for item in line) + \"\\n\")\n",
    "\n",
    "            # Обрабатываем данные для OCR\n",
    "            if not skip_ocr:\n",
    "                ocr_masks, texts = image_annotations[[\"points\", \"text\"]].values[0].tolist()\n",
    "                for num_mask, (mask, text) in enumerate(zip(ocr_masks, texts)):\n",
    "                    bbox = convert_mask_to_xy_bbox(mask)\n",
    "                    filename = Path(f\"{num_mask}_{image_name}\")\n",
    "                    out_path = recognizer_images_path / filename\n",
    "                    crop_and_save_polygon(image, str(out_path), mask, bbox)\n",
    "\n",
    "                    objects.append({\"file_name\": filename, \"text\": text})\n",
    "\n",
    "        # Сохранение данных OCR в CSV-файл\n",
    "        if objects:\n",
    "            ocr_data = pd.DataFrame(objects)\n",
    "            ocr_data.to_csv(Path(csv_root_path) / csv_name, index=False)\n",
    "        else:\n",
    "            print(f\"No OCR data was generated for {csv_name}.\")\n",
    "\n",
    "# Пример вызова функции\n",
    "process_image_data(yolo_data, train_images, valid_images, test_images,\n",
    "                   [\n",
    "                       [images_text_segmenter_train_dir, labels_text_segmenter_train_dir],\n",
    "                       [images_text_segmenter_valid_dir, labels_text_segmenter_valid_dir],\n",
    "                       [images_text_segmenter_test_dir, labels_text_segmenter_test_dir]\n",
    "                   ],\n",
    "                   [images_text_recognizer_train_dir, images_text_recognizer_valid_dir, images_text_recognizer_test_dir],\n",
    "                   [\"train.csv\", \"valid.csv\", \"test.csv\"],\n",
    "                   csv_root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f58d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd98890",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb97a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
